# -*- coding: utf-8 -*-
"""Final Project_Recommendation System_Movie.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D_ElP3CXb6S0UK_X5zM34QCPIjCVqStG

## 1. Import Library
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, regularizers

"""## 2. Data Understanding"""

directory = "./data"

data = {}

for file in os.listdir(directory):
    dataframe = os.path.splitext(file)[0]
    data[dataframe] = pd.read_csv(os.path.join(directory, file), delimiter=",")

"""### 2.1 Gathering Data"""

df_movies = data['movies']
df_movies

df_ratings = data['ratings']
df_ratings

"""### 2.2 Check the dimensions of the data"""

df_movies.shape

df_ratings.shape

"""## 3. Univariate Exploratory Data Analysis

#### Movies Dataset

Attribute  | Keterangan
------------- | -------------
movieId | merepresentasikan Id unik untuk setiap film
title | merepresentasikan judul untuk setiap film
genres | merepresentasikan genre untuk setiap film

#### Ratings Dataset

Attribute  | Keterangan
------------- | -------------
userId | merepresentasikan Id unik untuk setiap penonton
movieId | merepresentasikan Id unik untuk setiap film     
rating | merepresentasikan penilaian yang diberikan oleh penonton
timestamp | merepresentasikan waktu ketika penilaian diberikan

### 3.1 Mengecek tipe data pada setiap atribut
"""

df_movies.info()

df_ratings.info()

"""### 3.2 Mengecek deskripsi data pada dataframe"""

df_movies.describe(include='object')

df_ratings.describe()

"""### 3.3 Mengecek jumlah baris data dari setiap nilai unik"""

print('Jumlah Film: ', len(df_movies.movieId.value_counts()))
print('Jumlah Penonton: ', len(df_ratings.userId.value_counts()))

df_movies['genres'].value_counts()

df_ratings['rating'].value_counts().sort_index(ascending=False)

movie_stat = df_ratings.groupby('movieId').agg({'rating':'sum', 'userId': 'count'}).reset_index()
movie_stat.columns = ['movieId', 'rating', 'num_users']

result_df = pd.merge(df_movies, movie_stat, on='movieId')
result_df = result_df.sort_values(by='rating', ascending=False)
top_rated_movies = result_df.head(10)

top_rated_movies[['title', 'rating', 'num_users']]

movie_stats = df_ratings.groupby('movieId').agg({'rating': 'mean', 'userId': 'count'}).reset_index()
movie_stats.columns = ['movieId', 'average_rating', 'num_users']

result_df = pd.merge(df_movies, movie_stats, on='movieId')
result_df = result_df.sort_values(by='num_users', ascending=False)
most_rated_movies = result_df.head(10)

most_rated_movies[['title', 'average_rating', 'num_users']]

genre_stats = pd.merge(df_movies, movie_stats, on='movieId')
genre_stats = genre_stats.assign(genres=result_df['genres'].str.split('|')).explode('genres')

genre_stats = genre_stats.groupby('genres').agg({'average_rating': 'mean', 'num_users': 'sum'}).reset_index()
top_genre_ratings = genre_stats.sort_values(by='average_rating', ascending=False)
top_genre_ratings[['genres', 'average_rating', 'num_users']]

"""## 4. Visualisasi Data"""

plt.figure(figsize=(14, 14))

value_counts = df_movies['genres'].value_counts().head(10)
value_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)

plt.title('Distribusi Genre Film Teratas (Top 10)')
plt.ylabel('')

plt.show()

top_genre_ratings_sorted = top_genre_ratings.sort_values(by='num_users', ascending=True)

fig, ax1 = plt.subplots(figsize=(24, 12))

ax1.set_xlabel('Tata-rata Rating')
ax1.set_ylabel('Genres')
sns.barplot(x='average_rating', y='genres', data=top_genre_ratings_sorted, color='skyblue', ax=ax1, edgecolor='black')
ax1.tick_params(axis='x')

ax2 = ax1.twiny()
color = 'salmon'
ax2.set_xlabel('Jumlah Penonton', color=color)
ax2.plot(top_genre_ratings_sorted['num_users'], top_genre_ratings_sorted['genres'], color=color, marker='o')
ax2.tick_params(axis='x', labelcolor=color)

plt.yticks(fontsize=12)

ax1.grid(axis='x', linestyle='--', alpha=0.7)

fig.tight_layout()
plt.title('Distribusi Rata-rata Rating Penonton Terhadap Genre Film ', fontsize=16)
plt.show()

plt.figure(figsize=(16, 4))
rating = df_ratings['rating'].value_counts().sort_index().index
df_ratings['rating'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black')
plt.title('Distribusi rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah rating')
plt.xticks(rotation=0)
plt.show()

plt.figure(figsize=(10, 6))
plt.barh(top_rated_movies['title'], top_rated_movies['rating'], color='skyblue', edgecolor='black')
plt.xlabel('Jumlah Rating')
plt.title('Distribusi 10 Film Terbaik berdasarkan akumulasi Rating')
plt.gca().invert_yaxis()
plt.show()

fig, ax1 = plt.subplots(figsize=(16, 8))

color = 'skyblue'
ax1.set_xlabel('Rata-rata Rating')
ax1.set_ylabel('Film')
ax1.barh(most_rated_movies['title'], most_rated_movies['average_rating'], color=color, edgecolor='black')
ax1.tick_params(axis='x')

ax2 = ax1.twiny()
color = 'salmon'
ax2.set_xlabel('Jumlah Penonton', color=color)
ax2.plot(most_rated_movies['num_users'], most_rated_movies['title'], color=color, marker='o')
ax2.tick_params(axis='x', labelcolor=color)

plt.yticks(fontsize=12)

ax1.grid(axis='x', linestyle='--', alpha=0.7)

fig.tight_layout()
plt.title('Distribusi Film terpopuler berdasarkan rata-rata rating dan jumlah penonton (Top 10)', fontsize=16)
plt.show()

"""## 5. Data Preprocessing

### 5.1 Data Preparation

#### Movies Dataset

Mengatasi duplikasi data
"""

df_movies[df_movies['title'].duplicated()]

df_movies[df_movies['title'] == "Men with Guns (1997)"]

df_movies[df_movies['title'] == "War of the Worlds (2005)"]

df_movies.drop(df_movies.loc[df_movies['movieId'] == 26982].index, inplace=True)
df_movies.drop(df_movies.loc[df_movies['movieId'] == 64997].index, inplace=True)

df_movies[df_movies['title'].duplicated()]

"""Mengatasi Missing Value"""

df_movies.isnull().sum()

"""#### Ratings Dataset

Mengatasi duplikasi data
"""

df_ratings.duplicated().sum()

"""Mengatasi missing value"""

df_ratings.isnull().sum()

"""Menghapus atribut yang tidak dibutuhkan"""

df_ratings = df_ratings.drop(columns=['timestamp'])

"""## 7. Model Development dengan Content Based Filtering"""

movies_data = df_movies
movies_data.sample(5)

"""### 7.1 TF-IDF Vectorizer"""

tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(movies_data['genres'])
feature_names = pd.DataFrame(tfidf_vectorizer.get_feature_names_out(), columns=['Genre'])
feature_names

tfidf_matrix.shape

"""### 7.2 Mengubah matrix menjadi dense"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer.get_feature_names_out(),
    index=movies_data.title
).sample(24, axis=1).sample(5, axis=0)

"""### 7.3 Menghitung Derajat Kesamaan (Cosine Similarity)"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=movies_data['title'], columns=movies_data['title'])
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

cosine_sim_df.shape

"""#### 7.4 Mendapatkan Rekomendasi"""

def movie_recommendations(title, similarity_data=cosine_sim_df, items=movies_data[['title', 'genres']], k=5):

    index = similarity_data.loc[:, title].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]].drop(title, errors='ignore')
    recommendations = pd.DataFrame(closest).merge(items).head(k)

    return recommendations

"""### 7.5 Hasil Rekomendasi film berdasarkan genre"""

movies_data[movies_data.title.eq('Pulp Fiction (1994)')]

movie_recommendations('Pulp Fiction (1994)')

"""## 8. Model Development dengan Collaborative Filtering

### 8.1 Encoding atribut userId dan movieId
"""

ratings_data = df_ratings

user_to_user_encoded = {user_id: i for i, user_id in enumerate(ratings_data['userId'].unique())}
user_encoded_to_user = {i: user_id for i, user_id in enumerate(ratings_data['userId'].unique())}

movie_to_movie_encoded = {movie_id: i for i, movie_id in enumerate(ratings_data['movieId'].unique())}
movie_encoded_to_movie = {i: movie_id for i, movie_id in enumerate(ratings_data['movieId'].unique())}

ratings_data['user'] = ratings_data['userId'].map(user_to_user_encoded)
ratings_data['movie'] = ratings_data['movieId'].map(movie_to_movie_encoded)

num_users = len(user_to_user_encoded)
num_movies = len(movie_encoded_to_movie)
min_rating = ratings_data['rating'].min()
max_rating = ratings_data['rating'].max()

value = pd.DataFrame({'Value Count': [num_users, num_movies, min_rating, max_rating]},
                     index=['Number of User', 'Number of Movie', 'Min Rating', 'Max Rating'])

value

"""### 8.2 Membagi Data untuk Training dan Validasi"""

ratings_data = ratings_data.sample(frac=1, random_state=42)
ratings_data.sample(5)

x = ratings_data[['user', 'movie']].values
y = (ratings_data['rating'] - min_rating) / (max_rating - min_rating)

x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

print(x, y)

"""### 8.3 Proses Training"""

class RecommenderNet(Model):

  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size

    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=regularizers.l2(1e-6)
    )

    self.user_bias = layers.Embedding(num_users, 1)

    self.movie_embedding = layers.Embedding(
        num_movies,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=regularizers.l2(1e-6)
    )

    self.movie_bias = layers.Embedding(num_movies, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:, 0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_movies, 50)

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### 8.4 Mendapatkan Rekomendasi Film"""

movies = movies_data

# Mengambil sample user
user_id = ratings_data.userId.sample(1).iloc[0]
movie_watched_by_user = ratings_data[ratings_data.userId == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
movie_not_watched = movies[~movies['movieId'].isin(movie_watched_by_user.movieId.values)]['movieId']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""### 8.5 Hasil Rekomendasi film untuk User"""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]
# Showing Recommendations for Users
print('Showing Recommendations for User: {}'.format(user_id))
print('===' * 9)

# Movie with High Ratings from User
print('Movie with High Ratings from User')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows_user = movies[movies['movieId'].isin(top_movie_user)]
for row in movie_df_rows_user.itertuples():
    print(row.title, ':', row.genres)

print('----' * 8)

# Top 10 Movie Recommendation
print('Top 10 Movie Recommendations')
print('----' * 8)

recommended_movie = movies[movies['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)